{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f92ce4c",
   "metadata": {},
   "source": [
    "## Model serving with HSML\n",
    "\n",
    "In this example, we are going to serve the model that we created in the model training notebook.\n",
    "\n",
    "For the example to work, you need to have serving enabled in your project. In the settings tab for your project, select Serving to enable it. Now your UI should show a new tab called Model Serving.\n",
    "\n",
    "A model deployment (also called \"model serving\") can be created directly in the Hopsworks UI, by clicking on Model Serving and then on Create New Serving. In this example, however, we will create it through code with the HSML library.\n",
    "\n",
    "![tutorial-flow](images/end_to_end.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690d2f7f",
   "metadata": {},
   "source": [
    "### About Model Serving\n",
    "\n",
    "Models can be served via KFServing or \"default\" serving, which means a Docker container exposing a Flask server. For KFServing models, or models written in Tensorflow, you do not need to write a prediction file (see the section below). However, for sklearn models using default serving, you do need to proceed to write a prediction file.\n",
    "\n",
    "In order to use KFServing, you must have Kubernetes installed and enabled on your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a252b941",
   "metadata": {},
   "source": [
    "### Create the Prediction File\n",
    "\n",
    "In order to deploy a model, you need to write a Python file containing the logic to return a prediction from the model. Don't worry, this is usually a matter of just modifying some paths in a template script. An example can be seen in the code block below, where we have taken [this](https://hopsworks.readthedocs.io/en/latest/hopsml/python_model_serving.html#serving-python-based-models-on-hopsworks) Scikit-learn template script and changed two paths (see comments). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff60c660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing predict_example.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile predict_example.py\n",
    "from sklearn.externals import joblib\n",
    "from hops import hdfs # TODO this library should not be needed.\n",
    "\n",
    "class Predict(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" Initializes the serving state, reads a trained model from HDFS\"\"\"\n",
    "        self.model_path = \"Models/fraud_tutorial_model/1/model.pkl\" # Changed to our path.\n",
    "        print(\"Copying Scikit-Learn model from HDFS to local directory\")\n",
    "        hdfs.copy_to_local(self.model_path)\n",
    "        print(\"Reading local Scikit-Learn model for serving\")\n",
    "        self.model = joblib.load(\"./model.pkl\") # Changed to our path.\n",
    "        print(\"Initialization Complete\")\n",
    "\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        \"\"\" Serves a prediction request usign a trained model\"\"\"\n",
    "        return self.model.predict(inputs).tolist() # Numpy Arrays are not JSON serializable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab3f563",
   "metadata": {},
   "source": [
    "If you wonder why we use the path `Models/fraud_tutorial_model/1/model.pkl`, it is useful to know that the Data Sets tab in the Hopsworks UI lets you browse among the different files in the project. Registered models will be found underneath the `Models` directory. Since we saved our model with the name `fraud_tutorial_model`, that's the directory we should look in. `1` is just the version of the model we want to deploy.\n",
    "\n",
    "This script needs to be put into a known location in the Hopsworks file system. Let's call the file `predict_example.py` and put it in the `Models` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73f2e6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a763219a53d149789d557d252d4c613a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Uploading', max=800.0, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import hopsworks\n",
    "\n",
    "hopsworks_conn = hopsworks.connection()\n",
    "project = hopsworks_conn.get_project()\n",
    "dataset_api = project.get_dataset_api()\n",
    "\n",
    "uploaded_file_path = dataset_api.upload(\"predict_example.py\", \"Models\")\n",
    "predictor_script_path = os.path.join(\"/Projects\", project.name, uploaded_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c136414e",
   "metadata": {},
   "source": [
    "## Create the deployment\n",
    "\n",
    "Here, we fetch the model we want from the model registry and define a configuration for the deployment. For the configuration, we need to specify the serving type (default or KFserving) and in this case, since we use default serving and an sklearn model, we need to give the location of the prediction script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8855452d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hsml\n",
    "\n",
    "conn = hsml.connection()\n",
    "mr = conn.get_model_registry()\n",
    "\n",
    "# Use the model name from the previous notebook.\n",
    "model = mr.get_model(\"fraud_tutorial_model\", version=1)\n",
    "\n",
    "# Give it any name you want\n",
    "deployment = model.deploy(\n",
    "    name=\"frauddeployment\", \n",
    "    model_server=\"PYTHON\",\n",
    "    serving_tool=\"KSERVE\", #\"DEFAULT\",\n",
    "    script_file=predictor_script_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77298046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment: frauddeployment\n",
      "{\n",
      "    \"artifact_version\": 1,\n",
      "    \"batching_enabled\": false,\n",
      "    \"created\": \"2022-05-24T21:46:23.079Z\",\n",
      "    \"creator\": \"Admin Admin\",\n",
      "    \"id\": 1,\n",
      "    \"inference_logging\": \"ALL\",\n",
      "    \"kafka_topic_dto\": {\n",
      "        \"name\": \"CREATE\",\n",
      "        \"num_of_partitions\": 1,\n",
      "        \"num_of_replicas\": 1\n",
      "    },\n",
      "    \"model_name\": \"fraud_tutorial_model\",\n",
      "    \"model_path\": \"/Projects/fv_test/Models/fraud_tutorial_model\",\n",
      "    \"model_server\": \"PYTHON\",\n",
      "    \"model_version\": 1,\n",
      "    \"name\": \"frauddeployment\",\n",
      "    \"predictor\": \"predict_example.py\",\n",
      "    \"predictor_resource_config\": {\n",
      "        \"cores\": 1,\n",
      "        \"gpus\": 0,\n",
      "        \"memory\": 1024\n",
      "    },\n",
      "    \"requested_instances\": 1,\n",
      "    \"serving_tool\": \"KSERVE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Deployment: \" + deployment.name)\n",
    "deployment.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bf159b",
   "metadata": {},
   "source": [
    "The deployment has now been registered. However, to start it you need to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e443274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79204b3b410c4f269e3440f0e62f3fe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deployment.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5914fc4e",
   "metadata": {},
   "source": [
    "### Using the deployment\n",
    "\n",
    "Let's use the input example that we registered together with the model to query the deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "425045d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 0.0022940899903931, 0.9125449068314664, 0.6990882077784117, 0.249450252674718, 0.0022940899903931, 0.0022940899903931, 0.0022940899903931, 0.2687748826079058]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'predictions': [0]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs = [model.input_example]\n",
    "print(test_inputs)\n",
    "\n",
    "data = {\n",
    "    \"inputs\": test_inputs\n",
    "}\n",
    "\n",
    "deployment.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722bd7de",
   "metadata": {},
   "source": [
    "## TODO (Davit): gif how to model serving from the UI\n",
    "### Use REST endpoint \n",
    "\n",
    "You can also use a REST endpoint for your model. To do this you need to create an API key with 'serving' enabled, and retrieve the endpoint URL from the Model Serving UI.\n",
    "\n",
    "Go to the Model Serving UI and click on the eye icon next to a model to retrieve the endpoint URL. The shorter URL is an internal endpoint that you can only reach from within Hopsworks. If you want to call it from outside, you need one of the longer URLs. Make sure to use https instead of http. (**TODO this should be fixed**)\n",
    "\n",
    "### TODO (Davit): gif how to find endpoind and defind API key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfd15a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'predictions': [0]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "import hsml\n",
    "\n",
    "conn = hsml.connection()\n",
    "mr = conn.get_model_registry()\n",
    "\n",
    "# Use the model name from the previous notebook.\n",
    "model = mr.get_model(\"fraud_tutorial_model\", version=1)\n",
    "\n",
    "API_KEY = \"\"  # Put your API key here.\n",
    "MODEL_SERVING_ENDPOINT = \"\" # Put model serving endppoint here.\n",
    "HOST_NAME = \"\" # Put your hopsworks model serving endppoint here \n",
    "\n",
    "data = {\"inputs\": test_inputs}\n",
    "url = os.environ[\"REST_ENDPOINT\"] + MODEL_SERVING_ENDPOINT \n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\", \"Accept\": \"application/json\",\n",
    "    \"Authorization\": f\"ApiKey {API_KEY}\",\n",
    "    \"Host\": HOST_NAME}\n",
    "\n",
    "response = requests.post(url, verify=False, headers=headers, json=data)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff282cc1",
   "metadata": {},
   "source": [
    "### Stop Deployment\n",
    "\n",
    "To stop the deployment we simply run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e255701",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81568acc",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "In the next notebook we'll take a look at how to automate jobs in Hopsworks using Airflow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
